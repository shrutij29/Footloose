{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import psycopg2\n",
    "import os\n",
    "import json\n",
    "import csv\n",
    "import pandas as pd\n",
    "from datetime import datetime as dt\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plan:\n",
    "1) Data Collection\n",
    "    - prase the JSON files\n",
    "    - collect frames where there is only 1 person and the dance style is either ballet or tap\n",
    "2) Feature Extraction\n",
    "    - we have 17 keypoint coordinates we are looking at:\n",
    "        - nose, R/L eye, R/L ear, R/L shoulder, R/L elbow, R/L wrist, R/L hip, R/L knee, R/L ankle\n",
    "        - these coordinates will serve as our input data\n",
    "3) Split the data into train/validation/test sets\n",
    "4) Model\n",
    "    - classification model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "directory = '/Users/Shruti/Downloads/Dance_Dataset/densepose/txt'\n",
    "\n",
    "#get directories without hidden files\n",
    "directories = [d for d in os.listdir(directory) if os.path.isdir(os.path.join(directory, d))]\n",
    "directories.sort()\n",
    "\n",
    "#Setup dictionary to collect file names\n",
    "all_file_names = {}\n",
    "\n",
    "#Identify all file names\n",
    "for d in directories:\n",
    "    #get file names without hidden files\n",
    "    files = [f for f in os.listdir(os.path.join(directory, d)) if os.path.isfile(os.path.join(directory, d, f))]\n",
    "    files.sort()\n",
    "    all_file_names[d] = files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "latin\n"
     ]
    }
   ],
   "source": [
    "for d in directories:\n",
    "    if d == 'latin':\n",
    "        print('latin')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Count the number of videos in each video type\n",
    "#Determined by checking last number string on each image and\n",
    "#checking if it matches '0001'\n",
    "num_videos = {}\n",
    "first_img_indexes = {}\n",
    "\n",
    "for d in directories:\n",
    "    video_count = 0\n",
    "    num_images = len(all_file_names[d])\n",
    "    for i in range(num_images):\n",
    "        if all_file_names[d][i].split('.')[0].split('_')[-1] == '0001':\n",
    "            video_count += 1\n",
    "    num_videos[d] = video_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dance     | Num Images | Num Videos\n",
      "-----------------------------------\n",
      "ballet    | 22410      | 89\n",
      "break     | 25622      | 95\n",
      "cha       | 28098      | 98\n",
      "flamenco  | 24755      | 88\n",
      "foxtrot   | 23738      | 79\n",
      "jive      | 29100      | 106\n",
      "latin     | 24460      | 90\n",
      "pasodoble | 26607      | 98\n",
      "quickstep | 24036      | 82\n",
      "rumba     | 27262      | 94\n",
      "samba     | 25807      | 96\n",
      "square    | 27453      | 97\n",
      "swing     | 26337      | 95\n",
      "tango     | 24020      | 80\n",
      "tap       | 28541      | 95\n",
      "waltz     | 24380      | 80\n"
     ]
    }
   ],
   "source": [
    "#Print out summary results\n",
    "print(f\"{'dance':<9} | {'Num Images':<10} | {'Num Videos':<9}\")\n",
    "print(\"-\"*35)\n",
    "for k,v in all_file_names.items():\n",
    "    print(f'{k:<9} | {len(v):<10} | {num_videos[k]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function: Number of people in a frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def person_count(file_name):\n",
    "    '''Input a JSON file and get the number of people in each frame. '''\n",
    "    f = open(file_name, \"r\")\n",
    "    j = json.load(f)\n",
    "    f.close\n",
    "\n",
    "    people_count = len(j)\n",
    "\n",
    "    return people_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Testing results, should return 5\n",
    "peeps = person_count('/Users/Shruti/Downloads/Dance_Dataset/densepose/txt/ballet/-5Yp-vToI2E_016_0001.json')\n",
    "peeps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extract frames where the dance type is 'ballet' or 'tap' and there is just 1 person in the frame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def person_count(file_name):\n",
    "    '''Input a JSON file and get the number of people in each frame. '''\n",
    "    f = open(file_name, \"r\")\n",
    "    j = json.load(f)\n",
    "    f.close\n",
    "\n",
    "    people_count = len(j)\n",
    "\n",
    "    return people_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup lists to collect file paths\n",
    "selected_files_ballet = []\n",
    "selected_files_tap = []\n",
    "selected_files_latin = []\n",
    "\n",
    "# Identify all file names\n",
    "for d in directories:\n",
    "    if d == 'ballet':\n",
    "        # Get file names without hidden files\n",
    "        files = [f for f in os.listdir(os.path.join(directory, d)) if os.path.isfile(os.path.join(directory, d, f))]\n",
    "        files.sort()\n",
    "        for file_name in files:\n",
    "            file_path = os.path.join(directory, d, file_name)\n",
    "            # Count people in each frame\n",
    "            num_people = person_count(file_path)\n",
    "            if num_people == 1:  # Check if there is only one person\n",
    "                selected_files_ballet.append(file_path)\n",
    "    elif d == 'tap':\n",
    "        # Get file names without hidden files\n",
    "        files = [f for f in os.listdir(os.path.join(directory, d)) if os.path.isfile(os.path.join(directory, d, f))]\n",
    "        files.sort()\n",
    "        for file_name in files:\n",
    "            file_path = os.path.join(directory, d, file_name)\n",
    "            # Count people in each frame\n",
    "            num_people = person_count(file_path)\n",
    "            if num_people == 1:  # Check if there is only one person\n",
    "                selected_files_tap.append(file_path)\n",
    "    elif d == 'latin':\n",
    "        # Get file names without hidden files\n",
    "        files = [f for f in os.listdir(os.path.join(directory, d)) if os.path.isfile(os.path.join(directory, d, f))]\n",
    "        files.sort()\n",
    "        for file_name in files:\n",
    "            file_path = os.path.join(directory, d, file_name)\n",
    "            # Count people in each frame\n",
    "            num_people = person_count(file_path)\n",
    "            if num_people == 1:  # Check if there is only one person\n",
    "                selected_files_latin.append(file_path)\n",
    "\n",
    "# Print the sizes of the selected files lists\n",
    "print(\"Number of selected files for ballet:\", len(selected_files_ballet))\n",
    "print(\"Number of selected files for tap:\", len(selected_files_tap))\n",
    "print(\"Number of selected files for tap:\", len(selected_files_latin))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(selected_files_ballet[0])\n",
    "print(selected_files_tap[0])\n",
    "print(selected_files_latin[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Machine Learning Classification Model - Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_body_position_info(file_name):\n",
    "    '''Input a JSON file and get the body position of each person.  Outer list is\n",
    "    list of people.  Inner list is x,y position of each body part for that person'''\n",
    "    f = open(file_name, \"r\")\n",
    "    j = json.load(f)\n",
    "    f.close\n",
    "    people= []\n",
    "\n",
    "    for i,person in enumerate(j):\n",
    "        #Set up list to collect person's body location\n",
    "        person_i = []\n",
    "        count = 0\n",
    "\n",
    "        #add each body part position to the list\n",
    "        for body_part in person:\n",
    "            count+=1\n",
    "            if count == 1: continue\n",
    "            else: person_i.append(body_part[1])\n",
    "\n",
    "        #Append entire list to list of people\n",
    "        people.append(person_i)\n",
    "\n",
    "    return people"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_body_position_info(selected_files_latin[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_body_part_labels(file_name):\n",
    "    '''Input a JSON file and get the body position of each person.  Outer list is\n",
    "    list of people.  Inner list is x,y position of each body part for that person'''\n",
    "    f = open(file_name, \"r\")\n",
    "    j = json.load(f)\n",
    "    f.close()\n",
    "    \n",
    "    # Extract body part labels from the first person entry in the JSON file\n",
    "    body_part_labels = [body_part[0] for body_part in j[0][1:]]\n",
    "   \n",
    "    return body_part_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_body_part_labels(selected_files_latin[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Creating Feature Map**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenate the lists of selected files for ballet and tap dance styles\n",
    "all_selected_files = selected_files_ballet + selected_files_tap + selected_files_latin\n",
    "\n",
    "# Split data into training and testing sets\n",
    "train_files, test_files = train_test_split(all_selected_files, test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize lists to store feature data and corresponding labels\n",
    "train_feature_data = []\n",
    "train_feature_data_flattened = []\n",
    "\n",
    "train_labels = []\n",
    "\n",
    "# Iterate through each JSON file representing a frame in the training set\n",
    "for file_path in train_files:\n",
    "    # Get body position info for the single person in the frame\n",
    "    body_positions = get_body_position_info(file_path)\n",
    "    \n",
    "    train_feature_data.append(body_positions)\n",
    "\n",
    "    # Flatten the list of x, y positions\n",
    "    flattened_positions = [coord for point in body_positions for coord in point]\n",
    "    \n",
    "    # Append the flattened positions to the feature data list\n",
    "    train_feature_data_flattened.append(flattened_positions)\n",
    "    \n",
    "    # Determine the label based on the file path (e.g., ballet or tap)\n",
    "    if file_path in selected_files_ballet:\n",
    "        label = 'ballet'\n",
    "    elif file_path in selected_files_tap:\n",
    "        label = 'tap'\n",
    "    elif file_path in selected_files_latin:\n",
    "        label = 'latin'\n",
    "    else:\n",
    "        label = 'unknown'\n",
    "    train_labels.append(label)\n",
    "\n",
    "# Convert the training feature data and labels into numpy arrays\n",
    "X_train = np.array(train_feature_data)\n",
    "X_train_flattened = np.array(train_feature_data_flattened)\n",
    "y_train = np.array(train_labels)\n",
    "\n",
    "print(\"Number of frames (rows) in X_train:\", len(X_train_flattened))\n",
    "print(\"Number of features (columns) in X_train:\", len(X_train_flattened[0]))\n",
    "print(\"Number of labels in y_train:\", len(y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for row in X_train_flattened:\n",
    "    print(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for row in y_train:\n",
    "    print(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize lists to store feature data and corresponding labels for the testing set\n",
    "test_feature_data = []\n",
    "test_labels = []\n",
    "\n",
    "# Iterate through each JSON file representing a frame in the testing set\n",
    "for file_path in test_files:\n",
    "    # Get body position info for the single person in the frame\n",
    "    body_positions = get_body_position_info(file_path)\n",
    "    \n",
    "    # Flatten the list of x, y positions\n",
    "    flattened_positions = [coord for point in body_positions for coord in point]\n",
    "    \n",
    "    # Append the flattened positions to the feature data list for the testing set\n",
    "    test_feature_data.append(flattened_positions)\n",
    "\n",
    "     # Determine the label based on the file path (e.g., ballet or tap)\n",
    "    if file_path in selected_files_ballet:\n",
    "        label = 'ballet'\n",
    "    elif file_path in selected_files_tap:\n",
    "        label = 'tap'\n",
    "    elif file_path in selected_files_latin:\n",
    "        label = 'latin'\n",
    "    else:\n",
    "        label = 'unknown'\n",
    "    test_labels.append(label)\n",
    "\n",
    "# Convert the testing feature data and labels into numpy arrays\n",
    "X_test_flattened = np.array(test_feature_data)\n",
    "y_test = np.array(test_labels)\n",
    "\n",
    "print(\"Number of frames (rows) in X_test:\", len(X_test_flattened))\n",
    "print(\"Number of features (columns) in X_test:\", len(X_test_flattened[0]))\n",
    "print(\"Number of labels in y_test:\", len(y_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the body part labels\n",
    "body_part_labels = [\n",
    "    \"nose_x\", \"nose_y\", \n",
    "    \"left_eye_x\", \"left_eye_y\", \n",
    "    \"right_eye_x\", \"right_eye_y\", \n",
    "    \"left_ear_x\", \"left_ear_y\", \n",
    "    \"right_ear_x\", \"right_ear_y\", \n",
    "    \"left_shoulder_x\", \"left_shoulder_y\", \n",
    "    \"right_shoulder_x\", \"right_shoulder_y\", \n",
    "    \"left_elbow_x\", \"left_elbow_y\", \n",
    "    \"right_elbow_x\", \"right_elbow_y\", \n",
    "    \"left_wrist_x\", \"left_wrist_y\", \n",
    "    \"right_wrist_x\", \"right_wrist_y\", \n",
    "    \"left_hip_x\", \"left_hip_y\", \n",
    "    \"right_hip_x\", \"right_hip_y\", \n",
    "    \"left_knee_x\", \"left_knee_y\", \n",
    "    \"right_knee_x\", \"right_knee_y\", \n",
    "    \"left_ankle_x\", \"left_ankle_y\", \n",
    "    \"right_ankle_x\", \"right_ankle_y\"\n",
    "]\n",
    "\n",
    "# Create a dictionary to map body part labels to column indices\n",
    "body_part_mapping = {label: i for i, label in enumerate(body_part_labels)}\n",
    "\n",
    "# Access the x-coordinate of the left eye for all frames\n",
    "left_eye_x_coordinates = X_train_flattened[:, body_part_mapping[\"left_eye_x\"]]\n",
    "print(left_eye_x_coordinates)\n",
    "print(len(left_eye_x_coordinates))\n",
    "\n",
    "# Access the y-coordinate of the right shoulder for all frames\n",
    "right_shoulder_y_coordinates = X_train_flattened[:, body_part_mapping[\"right_shoulder_y\"]]\n",
    "# print(right_shoulder_y_coordinates)\n",
    "print(len(right_shoulder_y_coordinates))\n",
    "\n",
    "# Access both x and y coordinates of the nose for all frames\n",
    "nose_coordinates = X_train_flattened[:, [body_part_mapping[\"nose_x\"], body_part_mapping[\"nose_y\"]]]\n",
    "# print(nose_coordinates)\n",
    "print(len(nose_coordinates))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_train_flattened.shape)\n",
    "print(X_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.DataFrame(X_train.reshape(X_train.shape[0], -1), columns=body_part_labels)\n",
    "df_train['label'] = y_train\n",
    "df_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Model**\n",
    "\n",
    "X (feature matrix): \n",
    "- the x,y positions of the different body parts for each frame in our dataset\n",
    "- each row in the matrix corresponds to one frame\n",
    "- each column represents either the x or y position of a specific body part\n",
    "- there are a total of 17 attributes - nose, R/L eye, R/L ear, R/L shoulder, R/L elbow, R/L wrist, R/L hip, R/L knee, R/L ankle \n",
    "- our matrix has a total of 34 columns (17x2 for each x,y coordinate)\n",
    "- our matrix has a total of 15429 rows (8351 ballet frames; 7078 tap frames)\n",
    "\n",
    "Y (target variable)\n",
    "- represents the output label, in our case the dance style associated with each frame (ballet OR tap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_flattened_reshaped = X_train_flattened.reshape(X_train_flattened.shape[0], -1)\n",
    "X_test_flattened_reshaped = X_test_flattened.reshape(X_test_flattened.shape[0], -1)\n",
    "print(X_train_flattened_reshaped.shape)\n",
    "print(X_test_flattened_reshaped.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_flattened_reshaped = X_train_flattened.reshape(X_train_flattened.shape[0], -1)\n",
    "X_test_flattened_reshaped = X_test_flattened.reshape(X_test_flattened.shape[0], -1)\n",
    "\n",
    "# Initialize the Random Forest Classifier\n",
    "model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train_flattened_reshaped, y_train)\n",
    "\n",
    "# Make predictions on the test data\n",
    "y_pred = model.predict(X_test_flattened_reshaped)\n",
    "\n",
    "# Evaluate the model\n",
    "test_accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Test Accuracy:\", test_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(y_pred.shape)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
